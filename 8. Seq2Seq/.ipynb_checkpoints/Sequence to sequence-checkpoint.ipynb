{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence to sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "# os.environ['CUDA_VISIBLE_DEVICES']=\"\" # uncomment this line if you only use cpu\n",
    "import nltk\n",
    "import keras.backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers import Bidirectional, Input, Dense, Activation, Embedding, Dropout, TimeDistributed, GRU, Add, Lambda\n",
    "from keras.layers import dot, concatenate\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import Callback\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.nn import ctc_beam_search_decoder\n",
    "import tensorflow\n",
    "from numpy.random import seed\n",
    "seed(0)\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the Seq2Seq model to implement a tranlstion system which translates French text to English text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"C:\\Users\\trang\\Documents\\GitHub\\NLP\\8. \\Seq2Seq.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The architecture above uses one encoder RNN and one decoder RNN. The information passed from the encoder to the decoder is only the last hidden state of the encoder RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use GRU to encode and to encode and decode sequence information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_helper import load_translation_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The load_translation_data function:\n",
    "    1. Load French-English sentence pairs of the Tatoeba project (http://www.manythings.org/anki/) from the disk\n",
    "    2. Builds a vocabulary containing special tokens and words whose frequences are no less than 3 on the train set. \n",
    "     Special tokens:\n",
    "     \n",
    "     - <pad>  for padding\n",
    "     - <sos> for marking the beginning of sentence\n",
    "     - <eos> for marking the end of sentence\n",
    "     - <unk> for denoting the unknown words.\n",
    "   3. Maps sentences and labels to vectors based on the vocabulary\n",
    "   4. Returns the processed train and validation data for the encoder and decoder respectively, plus the built vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
